{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:This is an info message\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Set up the root logger to output DEBUG and higher level logs to console\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Now your custom logger will output messages at the INFO level and above\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info('This is an info message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognizer.utils.constants import DATASET_DIR, TARGET_TO_ENCODING\n",
    "from recognizer.utils.utils import get_metadata_from_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>subject</th>\n",
       "      <th>repetition</th>\n",
       "      <th>file</th>\n",
       "      <th>target_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>064</td>\n",
       "      <td>002</td>\n",
       "      <td>001</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>035</td>\n",
       "      <td>010</td>\n",
       "      <td>003</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>033</td>\n",
       "      <td>009</td>\n",
       "      <td>003</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>026</td>\n",
       "      <td>002</td>\n",
       "      <td>004</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>023</td>\n",
       "      <td>005</td>\n",
       "      <td>002</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target subject repetition  \\\n",
       "0    064     002        001   \n",
       "1    035     010        003   \n",
       "2    033     009        003   \n",
       "3    026     002        004   \n",
       "4    023     005        002   \n",
       "\n",
       "                                                file  target_encoding  \n",
       "0  /Users/facundopalavecino/Documents/DEV/ecd-tra...               63  \n",
       "1  /Users/facundopalavecino/Documents/DEV/ecd-tra...               34  \n",
       "2  /Users/facundopalavecino/Documents/DEV/ecd-tra...               32  \n",
       "3  /Users/facundopalavecino/Documents/DEV/ecd-tra...               25  \n",
       "4  /Users/facundopalavecino/Documents/DEV/ecd-tra...               22  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "targets = []\n",
    "subjects = []\n",
    "repetitions = []\n",
    "files = []\n",
    "\n",
    "for file in os.listdir(DATASET_DIR):\n",
    "    if \"left\" in file:\n",
    "        continue\n",
    "\n",
    "    target, subject, repetition = get_metadata_from_filename(file)\n",
    "\n",
    "    targets.append(target)\n",
    "    subjects.append(subject)\n",
    "    repetitions.append(repetition)\n",
    "    files.append(str((DATASET_DIR / file).resolve()))\n",
    "\n",
    "\n",
    "metadata = pd.DataFrame(\n",
    "    data={\n",
    "        \"target\": targets,\n",
    "        \"subject\": subjects,\n",
    "        \"repetition\": repetitions,\n",
    "        \"file\": files,\n",
    "    }\n",
    ")\n",
    "\n",
    "metadata[\"target_encoding\"] = metadata[\"target\"].map(TARGET_TO_ENCODING)\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "size = 1\n",
    "replace = False\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n",
    "\n",
    "testing_set = metadata.groupby([\"target\", \"subject\"], as_index=False).apply(fn)\n",
    "\n",
    "testing_set.index = testing_set.index.droplevel(0)\n",
    "\n",
    "training_set = metadata.loc[~metadata.index.isin(testing_set.index), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = training_set.sample(frac=0.3)\n",
    "testing_set = testing_set.sample(frac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    \"\"\"Permutes the element to match the format expected by PyTorch: (C<channels>, H<height>, W<width>)\"\"\"\n",
    "    # Transpose video from (T<frames>, Height, Width, Channels) to (Channels, Height, Width)\n",
    "    return x.permute(2, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/testing set: (768, 192)\n"
     ]
    }
   ],
   "source": [
    "from recognizer.dataset.image_dataset import ImageDataset\n",
    "\n",
    "training_dataset = ImageDataset(\n",
    "    video_filenames=training_set[\"file\"].values,\n",
    "    labels=training_set[\"target_encoding\"].values,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "testing_dataset = ImageDataset(\n",
    "    video_filenames=testing_set[\"file\"].values,\n",
    "    labels=testing_set[\"target_encoding\"].values,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "print(f\"Training/testing set: ({len(training_dataset)}, {len(testing_dataset)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 64\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from recognizer.models.simple_2d import Simple2DCNN\n",
    "\n",
    "model = Simple2DCNN(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:recognizer.trainers.trainer:Using device: mps\n"
     ]
    }
   ],
   "source": [
    "from recognizer.trainers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    loss_function=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    learning_rate=learning_rate,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]INFO:recognizer.trainers.trainer:Beginning training...\n",
      "INFO:recognizer.trainers.trainer:Epoch 1 | Batch 1...\n",
      "INFO:recognizer.trainers.trainer:Epoch 1 | Batch 2...\n",
      "INFO:recognizer.trainers.trainer:Epoch 1 | Batch 3...\n",
      "INFO:recognizer.trainers.trainer:Epoch 1 | Batch 4...\n",
      "INFO:recognizer.trainers.trainer:Epoch 1 | Batch 5...\n",
      "INFO:recognizer.trainers.trainer:Epoch 1 | Batch 6...\n",
      "INFO:recognizer.trainers.trainer:Epoch 1 | Batch 7...\n",
      "INFO:recognizer.trainers.trainer:Epoch 1 | Batch 8...\n",
      "INFO:recognizer.trainers.trainer:Epoch 1 | Batch 9...\n",
      "INFO:recognizer.trainers.trainer:Epoch 1 | Batch 10...\n",
      "INFO:recognizer.trainers.trainer:Epoch 1 | Batch 11...\n",
      "INFO:recognizer.trainers.trainer:Epoch 1 | Batch 12...\n",
      "12it [00:14,  1.24s/it]\n",
      "INFO:recognizer.trainers.trainer:Epoch 1, Training Loss: 12.88\n",
      "INFO:recognizer.trainers.trainer:Beginning of testing...\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.02s/it]\n",
      "INFO:recognizer.trainers.trainer:Epoch 1: Test Accuracy: 0.00\n",
      " 33%|███▎      | 1/3 [00:17<00:35, 17.97s/it]INFO:recognizer.trainers.trainer:Beginning training...\n",
      "INFO:recognizer.trainers.trainer:Epoch 2 | Batch 1...\n",
      "INFO:recognizer.trainers.trainer:Epoch 2 | Batch 2...\n",
      "INFO:recognizer.trainers.trainer:Epoch 2 | Batch 3...\n",
      "INFO:recognizer.trainers.trainer:Epoch 2 | Batch 4...\n",
      "INFO:recognizer.trainers.trainer:Epoch 2 | Batch 5...\n",
      "INFO:recognizer.trainers.trainer:Epoch 2 | Batch 6...\n",
      "INFO:recognizer.trainers.trainer:Epoch 2 | Batch 7...\n",
      "INFO:recognizer.trainers.trainer:Epoch 2 | Batch 8...\n",
      "INFO:recognizer.trainers.trainer:Epoch 2 | Batch 9...\n",
      "INFO:recognizer.trainers.trainer:Epoch 2 | Batch 10...\n",
      "INFO:recognizer.trainers.trainer:Epoch 2 | Batch 11...\n",
      "INFO:recognizer.trainers.trainer:Epoch 2 | Batch 12...\n",
      "12it [00:13,  1.15s/it]\n",
      "INFO:recognizer.trainers.trainer:Epoch 2, Training Loss: 16.84\n",
      "INFO:recognizer.trainers.trainer:Beginning of testing...\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.02it/s]\n",
      "INFO:recognizer.trainers.trainer:Epoch 2: Test Accuracy: 0.00\n",
      " 67%|██████▋   | 2/3 [00:34<00:17, 17.32s/it]INFO:recognizer.trainers.trainer:Beginning training...\n",
      "INFO:recognizer.trainers.trainer:Epoch 3 | Batch 1...\n",
      "INFO:recognizer.trainers.trainer:Epoch 3 | Batch 2...\n",
      "INFO:recognizer.trainers.trainer:Epoch 3 | Batch 3...\n",
      "INFO:recognizer.trainers.trainer:Epoch 3 | Batch 4...\n",
      "INFO:recognizer.trainers.trainer:Epoch 3 | Batch 5...\n",
      "INFO:recognizer.trainers.trainer:Epoch 3 | Batch 6...\n",
      "INFO:recognizer.trainers.trainer:Epoch 3 | Batch 7...\n",
      "INFO:recognizer.trainers.trainer:Epoch 3 | Batch 8...\n",
      "INFO:recognizer.trainers.trainer:Epoch 3 | Batch 9...\n",
      "INFO:recognizer.trainers.trainer:Epoch 3 | Batch 10...\n",
      "INFO:recognizer.trainers.trainer:Epoch 3 | Batch 11...\n",
      "INFO:recognizer.trainers.trainer:Epoch 3 | Batch 12...\n",
      "12it [00:13,  1.16s/it]\n",
      "INFO:recognizer.trainers.trainer:Epoch 3, Training Loss: 20.57\n",
      "INFO:recognizer.trainers.trainer:Beginning of testing...\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.06it/s]\n",
      "INFO:recognizer.trainers.trainer:Epoch 3: Test Accuracy: 0.00\n",
      "100%|██████████| 3/3 [00:51<00:00, 17.20s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epochs=3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ea6ed51ea6f425be360bb9fdd5cef85dc80933cab3801b73250c70e567767ea"
  },
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit ('ecd-trabajo-final-UlVdN89U-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
