{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognizer.utils.constants import ALL_DATASET_DIR, TARGET_TO_ENCODING\n",
    "from recognizer.utils.utils import get_metadata_from_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 64\n",
    "EPOCHS = 15"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>subject</th>\n",
       "      <th>repetition</th>\n",
       "      <th>file</th>\n",
       "      <th>target_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008</td>\n",
       "      <td>010</td>\n",
       "      <td>003</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>023</td>\n",
       "      <td>001</td>\n",
       "      <td>003</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>039</td>\n",
       "      <td>003</td>\n",
       "      <td>005</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>051</td>\n",
       "      <td>005</td>\n",
       "      <td>002</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010</td>\n",
       "      <td>007</td>\n",
       "      <td>001</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target subject repetition  \\\n",
       "0    008     010        003   \n",
       "1    023     001        003   \n",
       "2    039     003        005   \n",
       "3    051     005        002   \n",
       "4    010     007        001   \n",
       "\n",
       "                                                file  target_encoding  \n",
       "0  /Users/facundopalavecino/Documents/DEV/ecd-tra...                7  \n",
       "1  /Users/facundopalavecino/Documents/DEV/ecd-tra...               22  \n",
       "2  /Users/facundopalavecino/Documents/DEV/ecd-tra...               38  \n",
       "3  /Users/facundopalavecino/Documents/DEV/ecd-tra...               50  \n",
       "4  /Users/facundopalavecino/Documents/DEV/ecd-tra...                9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "targets = []\n",
    "subjects = []\n",
    "repetitions = []\n",
    "files = []\n",
    "\n",
    "for file in os.listdir(ALL_DATASET_DIR):\n",
    "    if \"left\" in file:\n",
    "        continue\n",
    "\n",
    "    target, subject, repetition = get_metadata_from_filename(file)\n",
    "\n",
    "    targets.append(target)\n",
    "    subjects.append(subject)\n",
    "    repetitions.append(repetition)\n",
    "    files.append(str((ALL_DATASET_DIR / file).resolve()))\n",
    "\n",
    "\n",
    "metadata = pd.DataFrame(\n",
    "    data={\n",
    "        \"target\": targets,\n",
    "        \"subject\": subjects,\n",
    "        \"repetition\": repetitions,\n",
    "        \"file\": files,\n",
    "    }\n",
    ")\n",
    "\n",
    "metadata[\"target_encoding\"] = metadata[\"target\"].map(TARGET_TO_ENCODING)\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "size = 1\n",
    "replace = False\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n",
    "\n",
    "testing_set = metadata.groupby([\"target\", \"subject\"], as_index=False).apply(fn)\n",
    "\n",
    "testing_set.index = testing_set.index.droplevel(0)\n",
    "\n",
    "training_set = metadata.loc[~metadata.index.isin(testing_set.index), :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    \"\"\"Permutes the element to match the format expected by PyTorch: (C<channels>, T<frames>, H<height>, W<width>)\"\"\"\n",
    "    # Transpose video from (T<frames>, H<height>, W<width>, C<channels>) to (C<channels>, T<frames>, H<height>, W<width>)\n",
    "    return x.permute(3, 0, 1, 2).float()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/testing set: (2560, 640)\n"
     ]
    }
   ],
   "source": [
    "from recognizer.dataset import SampledVideoDataset\n",
    "\n",
    "NUM_FRAMES = 4\n",
    "training_dataset = SampledVideoDataset(\n",
    "    video_filenames=training_set[\"file\"].values,\n",
    "    labels=training_set[\"target_encoding\"].values,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "testing_dataset = SampledVideoDataset(\n",
    "    video_filenames=testing_set[\"file\"].values,\n",
    "    labels=testing_set[\"target_encoding\"].values,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "print(f\"Training/testing set: ({len(training_dataset)}, {len(testing_dataset)})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Simple3DCNN(\n",
       "  (conv_layer): Sequential(\n",
       "    (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=131072, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=64, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from recognizer.models.simple_3d import Simple3DCNN\n",
    "\n",
    "model = Simple3DCNN(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device = \"cpu\" # RuntimeError: Conv3D is not supported on MPS\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "CMD = '''\n",
    "on run argv\n",
    "  display notification (item 2 of argv) with title (item 1 of argv) sound name \"Glass\"\n",
    "end run\n",
    "'''\n",
    "\n",
    "def notify(title, text):\n",
    "    subprocess.call(['osascript', '-e', CMD, title, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Beginning model training with parameters:\n",
      "- Epochs: 15\n",
      "- Batch Size: 128\n",
      "    \n",
      "INFO:__main__:Epoch 1 - Training\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "training_losses = []\n",
    "testing_losses = []\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "cm = None\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    logger.info(f\"\"\"\n",
    "Beginning model training with parameters:\n",
    "- Epochs: {EPOCHS}\n",
    "- Batch Size: {BATCH_SIZE}\n",
    "    \"\"\")\n",
    "\n",
    "    logger.info(f\"Epoch {epoch + 1} - Training\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for _, data in enumerate(train_loader):\n",
    "\n",
    "        batch, labels = data[0].float(), data[1]\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(batch)\n",
    "\n",
    "        loss = loss_function(logits, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_training_loss = running_loss / len(train_loader)\n",
    "    training_losses.append(average_training_loss)\n",
    "\n",
    "    logger.info(f\"AVG Training Loss: {average_training_loss:.2f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    logger.info(f\"Epoch {epoch + 1} - Evaluation\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data[0].float(), data[1]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(inputs)\n",
    "\n",
    "            _, preds = torch.max(logits, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu())\n",
    "            all_targets.extend(labels.cpu())\n",
    "\n",
    "            loss = loss_function(logits, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    average_testing_loss = running_loss / len(train_loader)\n",
    "    testing_losses.append(average_testing_loss)\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    accuracies.append(accuracy_score(all_targets, all_preds))\n",
    "    precisions.append(precision_score(all_targets, all_preds, average=\"macro\"))\n",
    "    recalls.append(recall_score(all_targets, all_preds, average=\"macro\"))\n",
    "    f1s.append(f1_score(all_targets, all_preds, average=\"macro\"))\n",
    "\n",
    "    if epoch == EPOCHS - 1:\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "    logger.info(f\"\"\"\n",
    "Epoch {epoch}:\n",
    "    - Accuracy  : {accuracies[-1]}\n",
    "    - Precision : {precisions[-1]}\n",
    "    - Recall    : {recalls[-1]}\n",
    "    - F1        : {f1s[-1]}\n",
    "    \"\"\")\n",
    "\n",
    "notify(\"Jupyterlab\", \"Entrenamiento del modelo terminado.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(data=cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy/Recall/Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "\n",
    "ax.plot(accuracies, label=\"Accuracy\", marker=\".\")\n",
    "ax.plot(precisions, label=\"Precision\", marker=\".\")\n",
    "ax.plot(recalls, label=\"Recall\", marker=\".\")\n",
    "#ax.plot(f1s, label=\"F1\")\n",
    "\n",
    "ax.set_xticks(range(0, epoch+1))\n",
    "ax.set_xticklabels(range(1, epoch+2))\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "\n",
    "ax.plot(training_losses, label=\"Training Loss\", marker=\".\", color=\"steelblue\")\n",
    "ax.plot(testing_losses, label=\"Evaluation Loss\", marker=\".\", color=\"orange\")\n",
    "\n",
    "ax.set_xticks(range(0, epoch+1))\n",
    "ax.set_xticklabels(range(1, epoch+2))\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognizer.utils.constants import ROOT_DIR\n",
    "\n",
    "MODELS_DIR = ROOT_DIR / \"models\"\n",
    "\n",
    "MODEL_PATH = MODELS_DIR / \"3d_model_2.pth\"\n",
    "\n",
    "with open(MODEL_PATH, \"w\") as f:\n",
    "        f.write(\"\")\n",
    "\n",
    "torch.save(model, f=MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recognizer-UlVdN89U-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
