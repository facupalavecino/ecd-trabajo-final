{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D NiN - MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognizer.utils.constants import ROOT_DIR, TARGET_TO_ENCODING\n",
    "from recognizer.utils.utils import get_metadata_from_filename\n",
    "\n",
    "DATASET_DIR_POSTA = ROOT_DIR / \"data\" / \"all-20percent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>subject</th>\n",
       "      <th>repetition</th>\n",
       "      <th>file</th>\n",
       "      <th>target_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>002</td>\n",
       "      <td>C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>003</td>\n",
       "      <td>C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>004</td>\n",
       "      <td>C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>005</td>\n",
       "      <td>C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target subject repetition  \\\n",
       "0    001     001        001   \n",
       "1    001     001        002   \n",
       "2    001     001        003   \n",
       "3    001     001        004   \n",
       "4    001     001        005   \n",
       "\n",
       "                                                file  target_encoding  \n",
       "0  C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...                0  \n",
       "1  C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...                0  \n",
       "2  C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...                0  \n",
       "3  C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...                0  \n",
       "4  C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...                0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "targets = []\n",
    "subjects = []\n",
    "repetitions = []\n",
    "files = []\n",
    "\n",
    "for file in os.listdir(DATASET_DIR_POSTA):\n",
    "\n",
    "    target, subject, repetition = get_metadata_from_filename(file)\n",
    "\n",
    "    targets.append(target)\n",
    "    subjects.append(subject)\n",
    "    repetitions.append(repetition)\n",
    "    files.append(str((DATASET_DIR_POSTA / file).resolve()))\n",
    "\n",
    "\n",
    "metadata = pd.DataFrame(\n",
    "    data={\n",
    "        \"target\": targets,\n",
    "        \"subject\": subjects,\n",
    "        \"repetition\": repetitions,\n",
    "        \"file\": files,\n",
    "    }\n",
    ")\n",
    "\n",
    "metadata[\"target_encoding\"] = metadata[\"target\"].map(TARGET_TO_ENCODING)\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "size = 1\n",
    "replace = False\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n",
    "\n",
    "testing_set = metadata.groupby([\"target\", \"subject\"], as_index=False).apply(fn)\n",
    "\n",
    "testing_set.index = testing_set.index.droplevel(0)\n",
    "\n",
    "training_set = metadata.loc[~metadata.index.isin(testing_set.index), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    \"\"\"Permutes the element to match the format expected by PyTorch: (C<channels>, T<frames>, H<height>, W<width>)\"\"\"\n",
    "    # Transpose video from (T<frames>, H<height>, W<width>, C<channels>) to (C<channels>, T<frames>, H<height>, W<width>)\n",
    "    return x.permute(3, 0, 1, 2).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 24\n",
    "NUM_CLASSES = 64\n",
    "NUM_FRAMES = 16\n",
    "EPOCHS = 50\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/testing set: (2560, 640)\n"
     ]
    }
   ],
   "source": [
    "from recognizer.dataset import SampledVideoDataset\n",
    "\n",
    "training_dataset = SampledVideoDataset(\n",
    "    video_filenames=training_set[\"file\"].values,\n",
    "    labels=training_set[\"target_encoding\"].values,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "testing_dataset = SampledVideoDataset(\n",
    "    video_filenames=testing_set[\"file\"].values,\n",
    "    labels=testing_set[\"target_encoding\"].values,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "print(f\"Training/testing set: ({len(training_dataset)}, {len(testing_dataset)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>subject</th>\n",
       "      <th>repetition</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_encoding</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 target  subject  repetition  file\n",
       "target_encoding                                   \n",
       "0                    10       10          10    10\n",
       "1                    10       10          10    10\n",
       "2                    10       10          10    10\n",
       "3                    10       10          10    10\n",
       "4                    10       10          10    10\n",
       "...                 ...      ...         ...   ...\n",
       "59                   10       10          10    10\n",
       "60                   10       10          10    10\n",
       "61                   10       10          10    10\n",
       "62                   10       10          10    10\n",
       "63                   10       10          10    10\n",
       "\n",
       "[64 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set.groupby(\"target_encoding\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_CLASSES = metadata.target_encoding.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognizer.models.nin import NiNVideoClassifier\n",
    "\n",
    "model = NiNVideoClassifier(\n",
    "    num_classes=NUM_CLASSES,\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([24, 64])\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(24, 3, 16, 216, 384).cuda()\n",
    "\n",
    "output = model(dummy_input)\n",
    "\n",
    "print(\"Output shape:\", output.shape)  # Should be [24, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 287552\n"
     ]
    }
   ],
   "source": [
    "p = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Params: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param: conv1.weight | Shape: torch.Size([32, 3, 3, 3, 3])\n",
      "Param: conv1.bias | Shape: torch.Size([32])\n",
      "Param: conv2.weight | Shape: torch.Size([64, 32, 3, 3, 3])\n",
      "Param: conv2.bias | Shape: torch.Size([64])\n",
      "Param: conv3.weight | Shape: torch.Size([128, 64, 3, 3, 3])\n",
      "Param: conv3.bias | Shape: torch.Size([128])\n",
      "Param: fc.weight | Shape: torch.Size([64, 128])\n",
      "Param: fc.bias | Shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(f\"Param: {n} | Shape: {p.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Experiment in MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "\n",
    "from mlflow.entities import Experiment\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "MLFLOW_TRACKING_SERVER_URI = \"http://localhost:5001\"\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"miniouser\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"miniopass\"\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://localhost:9000/\"\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_SERVER_URI)\n",
    "mlflow_client = MlflowClient(MLFLOW_TRACKING_SERVER_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/08 18:14:28 INFO mlflow.tracking.fluent: Experiment with name '3D NiN 01' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"3D NiN 01\"\n",
    "\n",
    "experiment: Experiment = mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'Execution 01' creado con ID '18bd0eb3c51b4431aa4cb7bcfc40b1a2'\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = \"Execution 01\"\n",
    "\n",
    "run = None\n",
    "\n",
    "matching_runs = mlflow_client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    filter_string=f\"tags.mlflow.runName = '{RUN_NAME}'\"\n",
    ")\n",
    "\n",
    "if len(matching_runs) > 0:\n",
    "    raise Exception(\"Pisando run existente!!!!!\")\n",
    "\n",
    "run = mlflow_client.create_run(experiment_id=experiment.experiment_id)\n",
    "\n",
    "mlflow_client.set_tag(run_id=run.info.run_id, key=\"mlflow.runName\", value=RUN_NAME)\n",
    "\n",
    "print(f\"Run '{RUN_NAME}' creado con ID '{run.info.run_id}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params successfully logged\n"
     ]
    }
   ],
   "source": [
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"BATCH_SIZE\", value=BATCH_SIZE)\n",
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"NUM_CLASSES\", value=NUM_CLASSES)\n",
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"EPOCHS\", value=EPOCHS)\n",
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"NUM_FRAMES\", value=NUM_FRAMES)\n",
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"LR\", value=LR)\n",
    "\n",
    "print(\"Params successfully logged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in environment variables.\n"
     ]
    }
   ],
   "source": [
    "mlflow_client.log_text(run_id=run.info.run_id, text=str(testing_set.index.values), artifact_file=\"testing set index.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "CMD = '''\n",
    "on run argv\n",
    "  display notification (item 2 of argv) with title (item 1 of argv) sound name \"Glass\"\n",
    "end run\n",
    "'''\n",
    "\n",
    "def notify(title, text):\n",
    "    subprocess.call(['osascript', '-e', CMD, title, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "cm = None\n",
    "\n",
    "metrics = {\n",
    "    \"training_loss\": [],\n",
    "    \"testing_loss\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning model training with parameters:\n",
      "- Epochs: 50\n",
      "- Batch Size: 24\n",
      "\n",
      "Epoch 1 - Training phase\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"\n",
    "Beginning model training with parameters:\n",
    "- Epochs: {EPOCHS}\n",
    "- Batch Size: {BATCH_SIZE}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "best_loss = np.inf\n",
    "patience = 3\n",
    "delta = 0.01\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1} - Training phase\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    running_training_loss = 0.0\n",
    "\n",
    "    for _, data in enumerate(train_loader):\n",
    "\n",
    "        batch, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        logits = model(batch)\n",
    "\n",
    "        loss = loss_function(logits, labels)\n",
    "\n",
    "        running_training_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_training_loss = running_training_loss / len(train_loader)\n",
    "    metrics[\"training_loss\"].append(round(average_training_loss, 2))\n",
    "\n",
    "    print(f\"    - AVG Training Loss: {average_training_loss:.2f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    print(f\"Epoch {epoch + 1} - Evaluation phase\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    running_testing_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            logits = model(inputs)\n",
    "\n",
    "            _, preds = torch.max(logits, 1)\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(labels.cpu())\n",
    "\n",
    "            loss = loss_function(logits, labels)\n",
    "            running_testing_loss += loss.item()\n",
    "\n",
    "    average_testing_loss = running_testing_loss / len(test_loader)\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "\n",
    "    assert len(all_preds) == len(all_targets) == 640\n",
    "    assert len(np.unique(all_targets)) == NUM_CLASSES\n",
    "\n",
    "    unique_preds = set(all_preds.numpy())\n",
    "    missing_classes = set(UNIQUE_CLASSES) - unique_preds\n",
    "\n",
    "    if missing_classes:\n",
    "        print(f\"    The following classes ({len(missing_classes)}) were not predicted: {missing_classes}\")\n",
    "\n",
    "    metrics[\"testing_loss\"].append(round(average_testing_loss, 2))\n",
    "    metrics[\"accuracy\"].append(accuracy_score(all_targets, all_preds))\n",
    "    metrics[\"precision\"].append(precision_score(all_targets, all_preds, average=\"macro\", zero_division=0, labels=UNIQUE_CLASSES))\n",
    "    metrics[\"recall\"].append(recall_score(all_targets, all_preds, average=\"macro\", zero_division=0, labels=UNIQUE_CLASSES))\n",
    "    metrics[\"f1\"].append(f1_score(all_targets, all_preds, average=\"macro\", zero_division=0, labels=UNIQUE_CLASSES))\n",
    "\n",
    "    for metric in metrics.keys():\n",
    "        mlflow_client.log_metric(\n",
    "            run_id=run.info.run_id,\n",
    "            key=metric,\n",
    "            value=metrics[metric][epoch],\n",
    "            step=epoch,\n",
    "        )\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    - Testing Loss: {metrics['testing_loss'][-1]}\n",
    "    - Accuracy  : {metrics['accuracy'][-1]}\n",
    "    - Precision : {metrics['precision'][-1]}\n",
    "    - Recall    : {metrics['recall'][-1]}\n",
    "    - F1        : {metrics['f1'][-1]}\n",
    "    \"\"\")\n",
    "\n",
    "    if average_testing_loss < best_loss - delta:\n",
    "        best_loss = average_testing_loss\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "    \n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered. Testing loss is not improving!\")\n",
    "        break\n",
    "\n",
    "    if epoch == EPOCHS - 1:\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_targets, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(data=cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy/Recall/Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "\n",
    "ax.plot(metrics[\"accuracy\"], label=\"Accuracy\", marker=\".\")\n",
    "ax.plot(metrics[\"precision\"], label=\"Precision\", marker=\".\")\n",
    "ax.plot(metrics[\"recall\"], label=\"Recall\", marker=\".\")\n",
    "ax.plot(metrics[\"f1\"], label=\"F1\", marker=\".\")\n",
    "\n",
    "ax.set_xticks(range(0, epoch+1))\n",
    "ax.set_xticklabels(range(1, epoch+2))\n",
    "ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "ax.set_yticklabels(np.arange(0, 1.1, 0.1))\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "\n",
    "ax.plot(metrics[\"training_loss\"], label=\"Training Loss\", marker=\".\", color=\"steelblue\")\n",
    "ax.plot(metrics[\"testing_loss\"], label=\"Evaluation Loss\", marker=\".\", color=\"orange\")\n",
    "\n",
    "ax.set_xticks(range(0, epoch+1))\n",
    "ax.set_xticklabels(range(1, epoch+2))\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from recognizer.utils.constants import ROOT_DIR\n",
    "\n",
    "MODELS_DIR = ROOT_DIR / \"models\"\n",
    "\n",
    "MODEL_PATH = MODELS_DIR / f\"{EXPERIMENT_NAME}_{RUN_NAME}.pth\"\n",
    "\n",
    "if MODEL_PATH.exists():\n",
    "        raise Exception(\"El modelo ya existe!!!!\")\n",
    "\n",
    "with open(MODEL_PATH, \"w\") as f:\n",
    "        f.write(\"\")\n",
    "\n",
    "torch.save(copy.deepcopy(model.state_dict()), f=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client.log_artifact(\n",
    "    run_id=run.info.run_id,\n",
    "    local_path=str(MODEL_PATH),\n",
    "    artifact_path=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Save the arrays to temporary npy files\n",
    "with tempfile.NamedTemporaryFile(suffix='.npy', delete=False) as f:\n",
    "    np.save(f, all_targets)\n",
    "    ground_truth_path = f.name\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    # Log the files to MLflow\n",
    "    mlflow_client.log_artifact(\n",
    "        run_id=run.info.run_id,\n",
    "        local_path=ground_truth_path, \n",
    "        artifact_path=\"ground_truth\"\n",
    "    )\n",
    "\n",
    "\n",
    "with tempfile.NamedTemporaryFile(suffix='.npy', delete=False) as f:\n",
    "    np.save(f, all_preds)\n",
    "    predictions_path = f.name\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    mlflow_client.log_artifact(\n",
    "        run_id=run.info.run_id,\n",
    "        local_path=predictions_path, \n",
    "        artifact_path=\"predictions\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "idx = random.randint(0, BATCH_SIZE-1)\n",
    "\n",
    "batch, klasses = next(iter(test_loader))\n",
    "\n",
    "sign_video = batch[idx]\n",
    "\n",
    "klass = klasses[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_video = sign_video.unsqueeze(0)\n",
    "sign_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "logits = model(sign_video.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Ground Truth: {klass}. Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading labels and preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "def load_preds_or_labels(run_id: str, artifact: Literal[\"predictions\", \"ground_truth\"]) -> np.ndarray:\n",
    "    ret_val = None\n",
    "    artifact_path = mlflow_client.download_artifacts(\n",
    "        run_id=run_id,\n",
    "        path=artifact,\n",
    "    )\n",
    "\n",
    "    for f in os.listdir(artifact_path):\n",
    "        data = np.load(Path(artifact_path) / f)\n",
    "        ret_val = np.concatenate([ret_val, data]) if ret_val is not None else data\n",
    "\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_preds = None\n",
    "loaded_labels = None\n",
    "\n",
    "loaded_preds = load_preds_or_labels(run_id=run.info.run_id, artifact=\"predictions\")\n",
    "loaded_labels = load_preds_or_labels(run_id=run.info.run_id, artifact=\"ground_truth\")\n",
    "\n",
    "loaded_preds.shape, loaded_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(loaded_labels, loaded_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2 = confusion_matrix(loaded_labels, loaded_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_TO_TARGET: dict[int, str] = {v: k for k, v in TARGET_TO_ENCODING.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_labels = TARGET_TO_ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognizer.utils.constants import TARGET_TO_WORD\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(24, 18), dpi=150, facecolor=\"white\")\n",
    "\n",
    "heatmap = sns.heatmap(data=cm2, ax=ax, annot=True, cmap=\"crest\")\n",
    "\n",
    "x_ticks = [int(label.get_text()) for label in heatmap.get_xticklabels()]\n",
    "y_ticks = [int(label.get_text()) for label in heatmap.get_yticklabels()]\n",
    "\n",
    "x_new_labels = [TARGET_TO_WORD[ENCODING_TO_TARGET[x]] for x in x_ticks]\n",
    "y_new_labels = [TARGET_TO_WORD[ENCODING_TO_TARGET[y]] for y in y_ticks]\n",
    "\n",
    "heatmap.set_xticklabels(x_new_labels)\n",
    "heatmap.set_yticklabels(y_new_labels)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recognizer-UlVdN89U-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
