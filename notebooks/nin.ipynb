{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network in Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "MLFLOW_TRACKING_SERVER_URI = \"http://localhost:20000\"\n",
    "MLFLOW_REGISTRY_SERVER_URI = \"http://localhost:20000\"\n",
    "mlflow_client = MlflowClient(MLFLOW_TRACKING_SERVER_URI, MLFLOW_REGISTRY_SERVER_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import Experiment\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_SERVER_URI)\n",
    "mlflow.set_registry_uri(MLFLOW_REGISTRY_SERVER_URI)\n",
    "\n",
    "experiment: Experiment = mlflow.set_experiment(experiment_name=\"NiN 01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow_client.create_run(\n",
    "    experiment_id=experiment.experiment_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognizer.utils.constants import ROOT_DIR, TARGET_TO_ENCODING\n",
    "from recognizer.utils.utils import get_metadata_from_filename\n",
    "\n",
    "DATASET_DIR_POSTA = ROOT_DIR / \"data\" / \"all-20percent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "NUM_CLASSES = 64\n",
    "EPOCHS = 30\n",
    "NUM_FRAMES = 8\n",
    "\n",
    "LR = 0.005\n",
    "\n",
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"BATCH_SIZE\", value=BATCH_SIZE)\n",
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"NUM_CLASSES\", value=NUM_CLASSES)\n",
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"EPOCHS\", value=EPOCHS)\n",
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"NUM_FRAMES\", value=NUM_FRAMES)\n",
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"LR\", value=LR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>subject</th>\n",
       "      <th>repetition</th>\n",
       "      <th>file</th>\n",
       "      <th>target_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>002</td>\n",
       "      <td>C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>003</td>\n",
       "      <td>C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>004</td>\n",
       "      <td>C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>005</td>\n",
       "      <td>C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target subject repetition  \\\n",
       "0    001     001        001   \n",
       "1    001     001        002   \n",
       "2    001     001        003   \n",
       "3    001     001        004   \n",
       "4    001     001        005   \n",
       "\n",
       "                                                file  target_encoding  \n",
       "0  C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...                0  \n",
       "1  C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...                0  \n",
       "2  C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...                0  \n",
       "3  C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...                0  \n",
       "4  C:\\Users\\facun\\Desktop\\DEV\\ecd-trabajo-final\\d...                0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "targets = []\n",
    "subjects = []\n",
    "repetitions = []\n",
    "files = []\n",
    "\n",
    "for file in os.listdir(DATASET_DIR_POSTA):\n",
    "\n",
    "    target, subject, repetition = get_metadata_from_filename(file)\n",
    "\n",
    "    targets.append(target)\n",
    "    subjects.append(subject)\n",
    "    repetitions.append(repetition)\n",
    "    files.append(str((DATASET_DIR_POSTA / file).resolve()))\n",
    "\n",
    "\n",
    "metadata = pd.DataFrame(\n",
    "    data={\n",
    "        \"target\": targets,\n",
    "        \"subject\": subjects,\n",
    "        \"repetition\": repetitions,\n",
    "        \"file\": files,\n",
    "    }\n",
    ")\n",
    "\n",
    "metadata[\"target_encoding\"] = metadata[\"target\"].map(TARGET_TO_ENCODING)\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "size = 1\n",
    "replace = False\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n",
    "\n",
    "testing_set = metadata.groupby([\"target\", \"subject\"], as_index=False).apply(fn)\n",
    "\n",
    "testing_set.index = testing_set.index.droplevel(0)\n",
    "\n",
    "training_set = metadata.loc[~metadata.index.isin(testing_set.index), :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    \"\"\"Permutes the element to match the format expected by PyTorch: (C<channels>, T<frames>, H<height>, W<width>)\"\"\"\n",
    "    # Transpose video from (T<frames>, H<height>, W<width>, C<channels>) to (C<channels>, T<frames>, H<height>, W<width>)\n",
    "    return x.permute(3, 0, 1, 2).float()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/testing set: (2560, 640)\n"
     ]
    }
   ],
   "source": [
    "from recognizer.dataset import SampledVideoDataset\n",
    "\n",
    "training_dataset = SampledVideoDataset(\n",
    "    video_filenames=training_set[\"file\"].values,\n",
    "    labels=training_set[\"target_encoding\"].values,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "testing_dataset = SampledVideoDataset(\n",
    "    video_filenames=testing_set[\"file\"].values,\n",
    "    labels=testing_set[\"target_encoding\"].values,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "print(f\"Training/testing set: ({len(training_dataset)}, {len(testing_dataset)})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from recognizer.models.nin import NiNVideoClassifier\n",
    "\n",
    "# Las imágenes del video son de 384x216 \n",
    "# Hay 8 frames por video\n",
    "\n",
    "# Es decir que cada elemento inut será de 3x8x216x382 (C<channels> * T<frames> * H<height> * W<width>)\n",
    "# Eso es un total de \n",
    "\n",
    "model = NiNVideoClassifier(\n",
    "    num_classes=NUM_CLASSES,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 3419776\n"
     ]
    }
   ],
   "source": [
    "p = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Params: {p}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "CMD = '''\n",
    "on run argv\n",
    "  display notification (item 2 of argv) with title (item 1 of argv) sound name \"Glass\"\n",
    "end run\n",
    "'''\n",
    "\n",
    "def notify(title, text):\n",
    "    subprocess.call(['osascript', '-e', CMD, title, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "cm = None\n",
    "\n",
    "metrics = {\n",
    "    \"training_loss\": [],\n",
    "    \"testing_loss\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning model training with parameters:\n",
      "- Epochs: 30\n",
      "- Batch Size: 8\n",
      "\n",
      "Epoch 1 - Training\n",
      "Epoch 1 - AVG Training Loss: 4.19\n",
      "Epoch 1 - Evaluation\n",
      "Epoch 1 - AVG Testing Loss: 4.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\facun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\recognizer-U-rlUTHu-py3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "    - Accuracy  : 0.015625\n",
      "    - Precision : 0.000244140625\n",
      "    - Recall    : 0.015625\n",
      "    - F1        : 0.0004807692307692308\n",
      "    \n",
      "Epoch 2 - Training\n",
      "Epoch 2 - AVG Training Loss: 4.16\n",
      "Epoch 2 - Evaluation\n",
      "Epoch 2 - AVG Testing Loss: 4.16\n",
      "\n",
      "Epoch 2:\n",
      "    - Accuracy  : 0.015625\n",
      "    - Precision : 0.000244140625\n",
      "    - Recall    : 0.015625\n",
      "    - F1        : 0.0004807692307692308\n",
      "    \n",
      "Epoch 3 - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\facun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\recognizer-U-rlUTHu-py3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - AVG Training Loss: 4.16\n",
      "Epoch 3 - Evaluation\n",
      "Epoch 3 - AVG Testing Loss: 4.16\n",
      "\n",
      "Epoch 3:\n",
      "    - Accuracy  : 0.015625\n",
      "    - Precision : 0.000244140625\n",
      "    - Recall    : 0.015625\n",
      "    - F1        : 0.0004807692307692308\n",
      "    \n",
      "Epoch 4 - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\facun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\recognizer-U-rlUTHu-py3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - AVG Training Loss: 4.16\n",
      "Epoch 4 - Evaluation\n",
      "Epoch 4 - AVG Testing Loss: 4.16\n",
      "\n",
      "Epoch 4:\n",
      "    - Accuracy  : 0.015625\n",
      "    - Precision : 0.000244140625\n",
      "    - Recall    : 0.015625\n",
      "    - F1        : 0.0004807692307692308\n",
      "    \n",
      "Epoch 5 - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\facun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\recognizer-U-rlUTHu-py3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - AVG Training Loss: 4.16\n",
      "Epoch 5 - Evaluation\n",
      "Epoch 5 - AVG Testing Loss: 4.16\n",
      "\n",
      "Epoch 5:\n",
      "    - Accuracy  : 0.015625\n",
      "    - Precision : 0.000244140625\n",
      "    - Recall    : 0.015625\n",
      "    - F1        : 0.0004807692307692308\n",
      "    \n",
      "Epoch 6 - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\facun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\recognizer-U-rlUTHu-py3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - AVG Training Loss: 4.16\n",
      "Epoch 6 - Evaluation\n",
      "Epoch 6 - AVG Testing Loss: 4.16\n",
      "\n",
      "Epoch 6:\n",
      "    - Accuracy  : 0.015625\n",
      "    - Precision : 0.000244140625\n",
      "    - Recall    : 0.015625\n",
      "    - F1        : 0.0004807692307692308\n",
      "    \n",
      "Epoch 7 - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\facun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\recognizer-U-rlUTHu-py3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m running_training_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m _, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m---> 18\u001b[0m     batch, labels \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device), data[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     20\u001b[0m     logits \u001b[39m=\u001b[39m model(batch)\n\u001b[0;32m     22\u001b[0m     loss \u001b[39m=\u001b[39m loss_function(logits, labels)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"\n",
    "Beginning model training with parameters:\n",
    "- Epochs: {EPOCHS}\n",
    "- Batch Size: {BATCH_SIZE}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1} - Training\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    running_training_loss = 0.0\n",
    "\n",
    "    for _, data in enumerate(train_loader):\n",
    "\n",
    "        batch, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        logits = model(batch)\n",
    "\n",
    "        loss = loss_function(logits, labels)\n",
    "\n",
    "        running_training_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_training_loss = running_training_loss / len(train_loader)\n",
    "    metrics[\"training_loss\"].append(round(average_training_loss, 2))\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} - AVG Training Loss: {average_training_loss:.2f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    print(f\"Epoch {epoch + 1} - Evaluation\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    running_testing_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            logits = model(inputs)\n",
    "\n",
    "            _, preds = torch.max(logits, 1)\n",
    "\n",
    "            all_preds.extend(preds.detach().cpu())\n",
    "            all_targets.extend(labels.detach().cpu())\n",
    "\n",
    "            loss = loss_function(logits, labels)\n",
    "            running_testing_loss += loss.item()\n",
    "\n",
    "    average_testing_loss = running_testing_loss / len(test_loader)\n",
    "    metrics[\"testing_loss\"].append(round(average_testing_loss, 2))\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} - AVG Testing Loss: {average_testing_loss:.2f}\")\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    metrics[\"accuracy\"].append(accuracy_score(all_targets, all_preds))\n",
    "    metrics[\"precision\"].append(precision_score(all_targets, all_preds, average=\"macro\"))\n",
    "    metrics[\"recall\"].append(recall_score(all_targets, all_preds, average=\"macro\"))\n",
    "    metrics[\"f1\"].append(f1_score(all_targets, all_preds, average=\"macro\"))\n",
    "\n",
    "    for metric in metrics.keys():\n",
    "        mlflow_client.log_metric(\n",
    "            run_id=run.info.run_id,\n",
    "            key=metric,\n",
    "            value=metrics[metric][epoch],\n",
    "            step=epoch,\n",
    "        )\n",
    "\n",
    "    if epoch == EPOCHS - 1:\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "    print(f\"\"\"\n",
    "Epoch {epoch + 1}:\n",
    "    - Accuracy  : {metrics['accuracy'][-1]}\n",
    "    - Precision : {metrics['precision'][-1]}\n",
    "    - Recall    : {metrics['recall'][-1]}\n",
    "    - F1        : {metrics['f1'][-1]}\n",
    "    \"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(data=cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy/Recall/Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "\n",
    "ax.plot(metrics[\"accuracy\"], label=\"Accuracy\", marker=\".\")\n",
    "ax.plot(metrics[\"precision\"], label=\"Precision\", marker=\".\")\n",
    "ax.plot(metrics[\"recall\"], label=\"Recall\", marker=\".\")\n",
    "ax.plot(metrics[\"f1\"], label=\"F1\", marker=\".\")\n",
    "\n",
    "ax.set_xticks(range(0, epoch+1))\n",
    "ax.set_xticklabels(range(1, epoch+2))\n",
    "ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "ax.set_yticklabels(np.arange(0, 1.1, 0.1))\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "\n",
    "ax.plot(metrics[\"training_loss\"], label=\"Training Loss\", marker=\".\", color=\"steelblue\")\n",
    "ax.plot(metrics[\"testing_loss\"], label=\"Evaluation Loss\", marker=\".\", color=\"orange\")\n",
    "\n",
    "ax.set_xticks(range(0, epoch+1))\n",
    "ax.set_xticklabels(range(1, epoch+2))\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognizer.utils.constants import ROOT_DIR\n",
    "\n",
    "MODELS_DIR = ROOT_DIR / \"models\"\n",
    "\n",
    "MODEL_PATH = MODELS_DIR / \"nin.pth\"\n",
    "\n",
    "with open(MODEL_PATH, \"w\") as f:\n",
    "        f.write(\"\")\n",
    "\n",
    "torch.save(model, f=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client.log_artifact(\n",
    "    run_id=run.info.run_id,\n",
    "    local_path=str(MODEL_PATH),\n",
    "    artifact_path=\"model.pth\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recognizer-UlVdN89U-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
