{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network in Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "MLFLOW_TRACKING_SERVER_URI = \"http://localhost:20000\"\n",
    "\n",
    "mlflow_client = MlflowClient(MLFLOW_TRACKING_SERVER_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import Experiment\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_SERVER_URI)\n",
    "\n",
    "experiment: Experiment = mlflow.set_experiment(experiment_name=\"NiN 01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow_client.create_run(\n",
    "    experiment_id=experiment.experiment_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognizer.utils.constants import ROOT_DIR, TARGET_TO_ENCODING\n",
    "from recognizer.utils.utils import get_metadata_from_filename\n",
    "\n",
    "DATASET_DIR_POSTA = ROOT_DIR / \"data\" / \"all-10percent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "INVALID_PARAMETER_VALUE: Changing param values is not allowed. Param with key='EPOCHS' was already logged with value='10' for run ID='8e3c448a4fb94fb0af916b1fbe782424'. Attempted logging new value '1'.\n\nThe cause of this error is typically due to repeated calls\nto an individual run_id event logging.\n\nIncorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    mlflow.log_param(\"depth\", 3)\n    mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will throw an MlflowException for overwriting a\nlogged parameter.\n\nCorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 3)\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will create a new nested run for each individual\nmodel and prevent parameter key collisions within the\ntracking store.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/recognizer-UlVdN89U-py3.9/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:297\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_param\u001b[0;34m(self, run_id, key, value)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 297\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49mlog_param(run_id, param)\n\u001b[1;32m    298\u001b[0m \u001b[39mexcept\u001b[39;00m MlflowException \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/recognizer-UlVdN89U-py3.9/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:211\u001b[0m, in \u001b[0;36mRestStore.log_param\u001b[0;34m(self, run_id, param)\u001b[0m\n\u001b[1;32m    208\u001b[0m req_body \u001b[39m=\u001b[39m message_to_json(\n\u001b[1;32m    209\u001b[0m     LogParam(run_uuid\u001b[39m=\u001b[39mrun_id, run_id\u001b[39m=\u001b[39mrun_id, key\u001b[39m=\u001b[39mparam\u001b[39m.\u001b[39mkey, value\u001b[39m=\u001b[39mparam\u001b[39m.\u001b[39mvalue)\n\u001b[1;32m    210\u001b[0m )\n\u001b[0;32m--> 211\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_endpoint(LogParam, req_body)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/recognizer-UlVdN89U-py3.9/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:59\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     58\u001b[0m response_proto \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mResponse()\n\u001b[0;32m---> 59\u001b[0m \u001b[39mreturn\u001b[39;00m call_endpoint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_host_creds(), endpoint, method, json_body, response_proto)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/recognizer-UlVdN89U-py3.9/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:203\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[1;32m    202\u001b[0m     response \u001b[39m=\u001b[39m http_request(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcall_kwargs)\n\u001b[0;32m--> 203\u001b[0m response \u001b[39m=\u001b[39m verify_rest_response(response, endpoint)\n\u001b[1;32m    204\u001b[0m js_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/recognizer-UlVdN89U-py3.9/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:135\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m _can_parse_as_json_object(response\u001b[39m.\u001b[39mtext):\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mraise\u001b[39;00m RestException(json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext))\n\u001b[1;32m    136\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mRestException\u001b[0m: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Param with key='EPOCHS' was already logged with value='10' for run ID='8e3c448a4fb94fb0af916b1fbe782424'. Attempted logging new value '1'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m mlflow_client\u001b[39m.\u001b[39mlog_param(run_id\u001b[39m=\u001b[39mrun\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id, key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBATCH_SIZE\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39mBATCH_SIZE)\n\u001b[1;32m      9\u001b[0m mlflow_client\u001b[39m.\u001b[39mlog_param(run_id\u001b[39m=\u001b[39mrun\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id, key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNUM_CLASSES\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39mNUM_CLASSES)\n\u001b[0;32m---> 10\u001b[0m mlflow_client\u001b[39m.\u001b[39;49mlog_param(run_id\u001b[39m=\u001b[39;49mrun\u001b[39m.\u001b[39;49minfo\u001b[39m.\u001b[39;49mrun_id, key\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEPOCHS\u001b[39;49m\u001b[39m\"\u001b[39;49m, value\u001b[39m=\u001b[39;49mEPOCHS)\n\u001b[1;32m     11\u001b[0m mlflow_client\u001b[39m.\u001b[39mlog_param(run_id\u001b[39m=\u001b[39mrun\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id, key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNUM_FRAMES\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39mNUM_FRAMES)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/recognizer-UlVdN89U-py3.9/lib/python3.9/site-packages/mlflow/tracking/client.py:806\u001b[0m, in \u001b[0;36mMlflowClient.log_param\u001b[0;34m(self, run_id, key, value)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_param\u001b[39m(\u001b[39mself\u001b[39m, run_id: \u001b[39mstr\u001b[39m, key: \u001b[39mstr\u001b[39m, value: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    752\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[39m    Log a parameter (e.g. model hyperparameter) against the run ID.\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[39m        status: FINISHED\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 806\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mlog_param(run_id, key, value)\n\u001b[1;32m    807\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/recognizer-UlVdN89U-py3.9/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:301\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_param\u001b[0;34m(self, run_id, key, value)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merror_code \u001b[39m==\u001b[39m ErrorCode\u001b[39m.\u001b[39mName(INVALID_PARAMETER_VALUE):\n\u001b[1;32m    300\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mmessage\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mPARAM_VALIDATION_MSG\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 301\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(msg, INVALID_PARAMETER_VALUE)\n\u001b[1;32m    302\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[0;31mMlflowException\u001b[0m: INVALID_PARAMETER_VALUE: Changing param values is not allowed. Param with key='EPOCHS' was already logged with value='10' for run ID='8e3c448a4fb94fb0af916b1fbe782424'. Attempted logging new value '1'.\n\nThe cause of this error is typically due to repeated calls\nto an individual run_id event logging.\n\nIncorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    mlflow.log_param(\"depth\", 3)\n    mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will throw an MlflowException for overwriting a\nlogged parameter.\n\nCorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 3)\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will create a new nested run for each individual\nmodel and prevent parameter key collisions within the\ntracking store."
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 24\n",
    "NUM_CLASSES = 64\n",
    "EPOCHS = 1\n",
    "NUM_FRAMES = 8\n",
    "\n",
    "LR = 0.005\n",
    "\n",
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"BATCH_SIZE\", value=BATCH_SIZE)\n",
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"NUM_CLASSES\", value=NUM_CLASSES)\n",
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"EPOCHS\", value=EPOCHS)\n",
    "mlflow_client.log_param(run_id=run.info.run_id, key=\"NUM_FRAMES\", value=NUM_FRAMES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>subject</th>\n",
       "      <th>repetition</th>\n",
       "      <th>file</th>\n",
       "      <th>target_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008</td>\n",
       "      <td>010</td>\n",
       "      <td>003</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>023</td>\n",
       "      <td>001</td>\n",
       "      <td>003</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>039</td>\n",
       "      <td>003</td>\n",
       "      <td>005</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>051</td>\n",
       "      <td>005</td>\n",
       "      <td>002</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010</td>\n",
       "      <td>007</td>\n",
       "      <td>001</td>\n",
       "      <td>/Users/facundopalavecino/Documents/DEV/ecd-tra...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target subject repetition  \\\n",
       "0    008     010        003   \n",
       "1    023     001        003   \n",
       "2    039     003        005   \n",
       "3    051     005        002   \n",
       "4    010     007        001   \n",
       "\n",
       "                                                file  target_encoding  \n",
       "0  /Users/facundopalavecino/Documents/DEV/ecd-tra...                7  \n",
       "1  /Users/facundopalavecino/Documents/DEV/ecd-tra...               22  \n",
       "2  /Users/facundopalavecino/Documents/DEV/ecd-tra...               38  \n",
       "3  /Users/facundopalavecino/Documents/DEV/ecd-tra...               50  \n",
       "4  /Users/facundopalavecino/Documents/DEV/ecd-tra...                9  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "targets = []\n",
    "subjects = []\n",
    "repetitions = []\n",
    "files = []\n",
    "\n",
    "for file in os.listdir(DATASET_DIR_POSTA):\n",
    "\n",
    "    target, subject, repetition = get_metadata_from_filename(file)\n",
    "\n",
    "    targets.append(target)\n",
    "    subjects.append(subject)\n",
    "    repetitions.append(repetition)\n",
    "    files.append(str((DATASET_DIR_POSTA / file).resolve()))\n",
    "\n",
    "\n",
    "metadata = pd.DataFrame(\n",
    "    data={\n",
    "        \"target\": targets,\n",
    "        \"subject\": subjects,\n",
    "        \"repetition\": repetitions,\n",
    "        \"file\": files,\n",
    "    }\n",
    ")\n",
    "\n",
    "metadata[\"target_encoding\"] = metadata[\"target\"].map(TARGET_TO_ENCODING)\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "size = 1\n",
    "replace = False\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n",
    "\n",
    "testing_set = metadata.groupby([\"target\", \"subject\"], as_index=False).apply(fn)\n",
    "\n",
    "testing_set.index = testing_set.index.droplevel(0)\n",
    "\n",
    "training_set = metadata.loc[~metadata.index.isin(testing_set.index), :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    \"\"\"Permutes the element to match the format expected by PyTorch: (C<channels>, T<frames>, H<height>, W<width>)\"\"\"\n",
    "    # Transpose video from (T<frames>, H<height>, W<width>, C<channels>) to (C<channels>, T<frames>, H<height>, W<width>)\n",
    "    return x.permute(3, 0, 1, 2).float()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/testing set: (2560, 640)\n"
     ]
    }
   ],
   "source": [
    "from recognizer.dataset import SampledVideoDataset\n",
    "\n",
    "training_dataset = SampledVideoDataset(\n",
    "    video_filenames=training_set[\"file\"].values,\n",
    "    labels=training_set[\"target_encoding\"].values,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "testing_dataset = SampledVideoDataset(\n",
    "    video_filenames=testing_set[\"file\"].values,\n",
    "    labels=testing_set[\"target_encoding\"].values,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "print(f\"Training/testing set: ({len(training_dataset)}, {len(testing_dataset)})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NiNVideoClassifier(\n",
       "  (nin_block1): Sequential(\n",
       "    (0): Conv3d(3, 192, kernel_size=(3, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (nin_block2): Sequential(\n",
       "    (0): Conv3d(192, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(160, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv3d(160, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (nin_block3): Sequential(\n",
       "    (0): Conv3d(160, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(96, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv3d(96, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "  (nin_block4): Sequential(\n",
       "    (0): Conv3d(96, 192, kernel_size=(3, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (nin_block5): Sequential(\n",
       "    (0): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (nin_block6): Sequential(\n",
       "    (0): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (nin_block7): Sequential(\n",
       "    (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (nin_block8): Sequential(\n",
       "    (0): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (nin_block9): Sequential(\n",
       "    (0): Conv3d(192, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (global_avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from recognizer.models.nin import NiNVideoClassifier\n",
    "\n",
    "# Las imágenes del video son de 384x216 \n",
    "# Hay 8 frames por video\n",
    "\n",
    "# Es decir que cada elemento inut será de 3x8x216x382 (C<channels> * T<frames> * H<height> * W<width>)\n",
    "# Eso es un total de \n",
    "\n",
    "model = NiNVideoClassifier(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device = \"cpu\" # RuntimeError: Conv3D is not supported on MPS\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "CMD = '''\n",
    "on run argv\n",
    "  display notification (item 2 of argv) with title (item 1 of argv) sound name \"Glass\"\n",
    "end run\n",
    "'''\n",
    "\n",
    "def notify(title, text):\n",
    "    subprocess.call(['osascript', '-e', CMD, title, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "metrics = {\n",
    "    \"training_loss\": [],\n",
    "    \"testing_loss\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "}\n",
    "\n",
    "cm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Beginning model training with parameters:\n",
      "- Epochs: 1\n",
      "- Batch Size: 24\n",
      "\n",
      "INFO:__main__: --- Epoch 1 - Training ---\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "logger.info(f\"\"\"\n",
    "Beginning model training with parameters:\n",
    "- Epochs: {EPOCHS}\n",
    "- Batch Size: {BATCH_SIZE}\n",
    "\"\"\")\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    logger.info(f\" --- Epoch {epoch + 1} - Training ---\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for _, data in enumerate(train_loader):\n",
    "\n",
    "        batch, labels = data[0].float(), data[1]\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(batch)\n",
    "\n",
    "        loss = loss_function(logits, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_training_loss = running_loss / len(train_loader)\n",
    "    training_losses.append(average_training_loss)\n",
    "\n",
    "    logger.info(f\"AVG Training Loss: {average_training_loss:.2f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    logger.info(f\" --- Epoch {epoch + 1} - Evaluation ---\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data[0].float(), data[1]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(inputs)\n",
    "\n",
    "            _, preds = torch.max(logits, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu())\n",
    "            all_targets.extend(labels.cpu())\n",
    "\n",
    "            loss = loss_function(logits, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    average_testing_loss = running_loss / len(train_loader)\n",
    "    metrics[\"testing_loss\"].append(average_testing_loss)\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics[\"accuracy\"].append(accuracy_score(all_targets, all_preds))\n",
    "    metrics[\"precision\"].append(precision_score(all_targets, all_preds, average=\"macro\"))\n",
    "    metrics[\"recall\"].append(recall_score(all_targets, all_preds, average=\"macro\"))\n",
    "    metrics[\"f1\"].append(f1_score(all_targets, all_preds, average=\"macro\"))\n",
    "\n",
    "    for metric in metrics.keys():\n",
    "        mlflow_client.log_metric(\n",
    "            run_id=run.info.run_id,\n",
    "            key=metric,\n",
    "            value=metrics[metric][-1],\n",
    "            step=epoch,\n",
    "        )\n",
    "\n",
    "    if epoch == EPOCHS - 1:\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "    logger.info(f\"\"\"\n",
    "    Epoch {epoch + 1}:\n",
    "    - Accuracy  : {accuracies[-1]}\n",
    "    - Precision : {precisions[-1]}\n",
    "    - Recall    : {recalls[-1]}\n",
    "    - F1        : {f1s[-1]}\n",
    "    \"\"\")\n",
    "\n",
    "notify(\"Jupyterlab\", \"Entrenamiento del modelo terminado.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(data=cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy/Recall/Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "\n",
    "ax.plot(metrics[\"accuracy\"], label=\"Accuracy\", marker=\".\")\n",
    "ax.plot(metrics[\"precision\"], label=\"Precision\", marker=\".\")\n",
    "ax.plot(metrics[\"recall\"], label=\"Recall\", marker=\".\")\n",
    "ax.plot(metrics[\"f1\"], label=\"F1\", marker=\".\")\n",
    "\n",
    "ax.set_xticks(range(0, epoch+1))\n",
    "ax.set_xticklabels(range(1, epoch+2))\n",
    "ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "ax.set_yticklabels(np.arange(0, 1.1, 0.1))\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "\n",
    "ax.plot(metrics[\"training_loss\"], label=\"Training Loss\", marker=\".\", color=\"steelblue\")\n",
    "ax.plot(metrics[\"testing_loss\"], label=\"Evaluation Loss\", marker=\".\", color=\"orange\")\n",
    "\n",
    "ax.set_xticks(range(0, epoch+1))\n",
    "ax.set_xticklabels(range(1, epoch+2))\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognizer.utils.constants import ROOT_DIR\n",
    "\n",
    "MODELS_DIR = ROOT_DIR / \"models\"\n",
    "\n",
    "MODEL_PATH = MODELS_DIR / \"nin.pth\"\n",
    "\n",
    "# with open(MODEL_PATH, \"w\") as f:\n",
    "#         f.write(\"\")\n",
    "\n",
    "# torch.save(model, f=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client.log_artifact(\n",
    "    run_id=run.info.run_id,\n",
    "    local_path=str(MODEL_PATH),\n",
    "    artifact_path=\"model.pth\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recognizer-UlVdN89U-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
